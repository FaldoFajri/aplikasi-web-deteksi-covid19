{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FaldoFajri/tubes-mesinbelajar/blob/main/Final_Code_Model_Transfer_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/FaldoFajri/tubes-mesinbelajar.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E25WVeiaGu5f",
        "outputId": "b6e4ede0-6df3-40da-8999-1377cdf8d4fa"
      },
      "id": "E25WVeiaGu5f",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'tubes-mesinbelajar'...\n",
            "remote: Enumerating objects: 2534, done.\u001b[K\n",
            "remote: Counting objects: 100% (2534/2534), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2492/2492), done.\u001b[K\n",
            "remote: Total 2534 (delta 25), reused 2534 (delta 25), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (2534/2534), 1.49 GiB | 13.92 MiB/s, done.\n",
            "Resolving deltas: 100% (25/25), done.\n",
            "Checking out files: 100% (2603/2603), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a6839db",
      "metadata": {
        "id": "2a6839db"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt \n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63643a7a",
      "metadata": {
        "id": "63643a7a"
      },
      "outputs": [],
      "source": [
        "test_dir = \"/content/tubes-mesinbelajar/dataset/test\"\n",
        "train_dir = \"/content/tubes-mesinbelajar/dataset/train\"\n",
        "val_dir = \"/content/tubes-mesinbelajar/dataset/val\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38f74d62",
      "metadata": {
        "id": "38f74d62"
      },
      "outputs": [],
      "source": [
        "#DISINI SAYA MENGGUNAKAN MODEL VGG16\n",
        "\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(100,100,3))\n",
        "base_model.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5187f141",
      "metadata": {
        "id": "5187f141",
        "outputId": "f3e98c35-e656-430d-8d06-fe53e8de0a44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 100, 100, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 100, 100, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 100, 100, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 50, 50, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 50, 50, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 50, 50, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 25, 25, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 25, 25, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 25, 25, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 25, 25, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 12, 12, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 12, 12, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 6, 6, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 0\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f567f550",
      "metadata": {
        "id": "f567f550"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "flatten_layer = layers.Flatten()\n",
        "dense_layer_1 = layers.Dense(64, activation='relu')\n",
        "dense_layer_2 = layers.Dense(20, activation='relu')\n",
        "prediction_layer = layers.Dense(2, activation='softmax')\n",
        "\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    flatten_layer,\n",
        "    dense_layer_1,\n",
        "    prediction_layer\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f753eff5",
      "metadata": {
        "id": "f753eff5"
      },
      "outputs": [],
      "source": [
        "image_shape = (100,100,3)\n",
        "image_gen = ImageDataGenerator(rotation_range=20,\n",
        "                               width_shift_range=0.10,\n",
        "                               height_shift_range=0.10,\n",
        "                               rescale=1/255,\n",
        "                               shear_range=0.1,\n",
        "                               zoom_range=0.1,\n",
        "                               horizontal_flip=True,\n",
        "                               fill_mode='nearest')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ec18e5d",
      "metadata": {
        "id": "3ec18e5d",
        "outputId": "2cd91166-c4ec-4a7f-a0a8-5dc2e0b3469b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1511 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_image_gen = image_gen.flow_from_directory(train_dir,\n",
        "                                               target_size=(100,100),\n",
        "                                               batch_size=32,\n",
        "                                               class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e322523b",
      "metadata": {
        "id": "e322523b",
        "outputId": "4171758b-7903-4ae1-c839-a676cbb270e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 215 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "val_image_gen = image_gen.flow_from_directory(val_dir,\n",
        "                                               target_size=(100,100),\n",
        "                                               batch_size=32,\n",
        "                                               class_mode='categorical',shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e385658",
      "metadata": {
        "id": "4e385658",
        "outputId": "f54ab974-1e0b-4c2e-aabd-34ec0786f1ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 432 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "test_image_gen = image_gen.flow_from_directory(test_dir,\n",
        "                                               target_size=(100,100),\n",
        "                                               batch_size=32,\n",
        "                                               class_mode='categorical',shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89a976be",
      "metadata": {
        "id": "89a976be"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "# Compile model\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(lr=0.000024),\n",
        "              metrics=['acc'])\n",
        "\n",
        "#es = EarlyStopping(monitor='val_acc', mode='max', patience=5, restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c17d22b",
      "metadata": {
        "id": "0c17d22b",
        "outputId": "68ce20e8-3189-45ce-9faa-5e70fda7eebc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "48/48 [==============================] - 206s 3s/step - loss: 0.5378 - acc: 0.7340 - val_loss: 0.4804 - val_acc: 0.7349\n",
            "Epoch 2/100\n",
            "48/48 [==============================] - 118s 2s/step - loss: 0.4311 - acc: 0.7704 - val_loss: 0.3800 - val_acc: 0.8279\n",
            "Epoch 3/100\n",
            "48/48 [==============================] - 135s 3s/step - loss: 0.3504 - acc: 0.8478 - val_loss: 0.3182 - val_acc: 0.9023\n",
            "Epoch 4/100\n",
            "48/48 [==============================] - 144s 3s/step - loss: 0.2823 - acc: 0.9272 - val_loss: 0.2632 - val_acc: 0.9209\n",
            "Epoch 5/100\n",
            "48/48 [==============================] - 106s 2s/step - loss: 0.2350 - acc: 0.9457 - val_loss: 0.2283 - val_acc: 0.9488\n",
            "Epoch 6/100\n",
            "26/48 [===============>..............] - ETA: 43s - loss: 0.2011 - acc: 0.9641"
          ]
        }
      ],
      "source": [
        "results = model.fit(train_image_gen,epochs=100, validation_data=val_image_gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad456695",
      "metadata": {
        "id": "ad456695"
      },
      "outputs": [],
      "source": [
        "loss_df = pd.DataFrame(model.history.history)\n",
        "loss_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "877a57df",
      "metadata": {
        "id": "877a57df"
      },
      "outputs": [],
      "source": [
        "loss_df[['acc', 'val_acc']].plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d4fb2d7",
      "metadata": {
        "id": "4d4fb2d7"
      },
      "outputs": [],
      "source": [
        "loss_df[['loss', 'val_loss']].plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02fe3f0b",
      "metadata": {
        "id": "02fe3f0b"
      },
      "outputs": [],
      "source": [
        "predictions = np.argmax(model.predict(test_image_gen), axis = -1)\n",
        "predictions\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(classification_report(test_image_gen.classes,predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e59b3174",
      "metadata": {
        "id": "e59b3174"
      },
      "outputs": [],
      "source": [
        "print(confusion_matrix(test_image_gen.classes,predictions))\n",
        "sns.heatmap(confusion_matrix(test_image_gen.classes,predictions), annot = True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "colab": {
      "name": "Final Code Model Transfer Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}